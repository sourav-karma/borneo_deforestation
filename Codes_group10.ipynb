{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"d3b0b4845b934d019ec84ae35ba4183a","deepnote_cell_type":"text-cell-h1","formattedRanges":[]},"source":["# Quantifying tropical deforestation driven by oil palm cultivation in Borneo Island, Indonesia"]},{"cell_type":"markdown","metadata":{"cell_id":"637a871a01794b119d4c30b09aa958bd","deepnote_cell_type":"text-cell-h2","formattedRanges":[]},"source":["## 0. Import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"2a12ba8b6bde427a9290cb9cb48ee64b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2259,"execution_start":1685100385793,"source_hash":"dcec18eb"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'rasterio'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn [1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rasterio'"]}],"source":["import glob, os, time\n","import numpy as np\n","import pandas as pd\n","import geopandas as gpd\n","import numpy as np\n","import rasterio\n","import shutil\n","import matplotlib.pyplot as plt\n","import sklearn\n","from pathlib import Path\n","from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, classification_report\n","from rasterio import features\n","from scipy.ndimage import median_filter\n","\n","\n"]},{"cell_type":"markdown","metadata":{"cell_id":"78f6a1592eca4ed4befed961c979ee8d","deepnote_cell_type":"text-cell-h2","formattedRanges":[]},"source":["## 1. Download of monthly composite from GEE"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"4955a67b72684e04b476952c149c4c42","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"execution_millis":16,"execution_start":1685087063191,"source_hash":"2cc0058b"},"outputs":[],"source":["// Define start and end dates for the loop\n","//change start and end year get the monthly products of those years dowmloaded in google drive\n","var startYear = 2017;\n","var endYear = 2021;\n","\n","// create a loop that iterates through each year and each month within that year.   \n","\n","// Loop through each year\n","for (var year=startYear; year<=endYear; year++) {\n","  // Loop through each month\n","  for (var month=1; month<=12; month++) {\n","    \n","    // Define start and end dates for the current month\n","    var startDate = ee.Date.fromYMD(year, month, 1);\n","    var endDate = startDate.advance(1, 'month');\n","    \n","    // Filter the image collection by date and clip to the ROI\n","    var collectionVH = ee.ImageCollection('COPERNICUS/S1_GRD')\n","      .filter(ee.Filter.eq('instrumentMode', 'IW'))\n","      .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')) //select VV for downloading VV\n","      .filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'))\n","      .filterBounds(roi)\n","      .select(['VH'])                                                          //select VV for downloading VV \n","      .filterDate(startDate, endDate);\n","    \n","    // Check if the collection is not empty\n","    var count = collectionVH.size().getInfo();\n","    if (count === 0) {\n","      print('No images found for ' + startDate.format('YYYY-MM-dd') + ' to ' + endDate.format('YYYY-MM-dd'));\n","      continue;\n","    }\n","    \n","    // Create a monthly median composite and clip to the ROI\n","    var monthlyComposite = collectionVH.median().clip(roi);\n","    \n","    // Define the export parameters\n","    var exportName = ee.String('s1_VH_median_').cat(startDate.format('YYYY-MM')).cat('_cliped');\n","    var exportFolder = 'LBRAT2104/poster';\n","    var exportScale = 10;\n","\n","    // Export the image to Google Drive\n","    Export.image.toDrive({\n","      image: monthlyComposite,\n","      description: exportName.getInfo(),\n","      folder: exportFolder,\n","      scale: exportScale,\n","      maxPixels: 1e13,\n","      region: roi\n","    });\n","    \n","  }\n","}"]},{"cell_type":"markdown","metadata":{"cell_id":"2f83eb6423c24ed0a6854f62d7bf5f80","deepnote_cell_type":"text-cell-h2","formattedRanges":[]},"source":["## 2. Normalization "]},{"cell_type":"markdown","metadata":{"cell_id":"c4efe37b48e145b68d738fbcf04600bc","deepnote_cell_type":"text-cell-p","formattedRanges":[]},"source":["The first step is to load the images (here VH but it must also be done for VV)."]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"ee915ca89b46469d8ee061071cc3820b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"execution_millis":556,"execution_start":1684314354182,"source_hash":"b2a0a490"},"outputs":[],"source":["# Set the directory path\n","dir_path = 'X:\\STUDENTS\\GROUP_10\\S1 images\\VH'\n","\n","# Get the list of file names in the directory\n","file_names = os.listdir(dir_path)\n","\n","# Initialize an empty list to store the images\n","images = []\n","\n","# Loop over the file names and load each image into a NumPy array\n","for file_name in file_names:\n","        # Load the image into a NumPy array\n","        with rasterio.open(os.path.join(dir_path, file_name)) as dataset:\n","            image = dataset.read(1)\n","        # Append the image to the list of images\n","        images.append(image)       \n","\n","print(file_names)"]},{"cell_type":"markdown","metadata":{"cell_id":"47c972ec39bf4cdb8a6eb794f81dfec8","deepnote_cell_type":"markdown"},"source":["To normalize an image, the following formula is used:\n","\n","$image_{normalized} = (image - median_ {2years})/St. Dev. _{2years}$\n","\n"]},{"cell_type":"markdown","metadata":{"cell_id":"dd0a98633ced4d2184d361524c343242","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Calculation of the median for all images"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"87d1031ec48e4911b1a60b696726b211","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"ea8f4a0c"},"outputs":[],"source":["# Convert the list of images to a NumPy array\n","images_array = np.array(images)\n","\n","# Initialize an empty list to store the median images\n","median_images = []\n","\n","# Loop over the images and compute the median of each group of 24 images\n","for i in range(1, len(images_array) - 23):\n","    group = images_array[i-1:i+23]\n","    median_image = np.median(group, axis=0)\n","    median_images.append(median_image)\n","\n","# Stack the median images into a multi-dimensional array\n","stacked_median_images = np.stack(median_images)\n","\n","# Set the output file name\n","output_file = 'stacked_median_images.npy'\n","\n","# Save the stacked_median_images array as a numpy file\n","np.save(output_file, stacked_median_images)"]},{"cell_type":"markdown","metadata":{"cell_id":"0d9594c44f064d00afef5ae38b1ae344","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Calculation of the standard deviation for all images"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"d32d1f8f2f1941a6860d849398300b59","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"65c26992"},"outputs":[],"source":["\n","# Convert the list of images to a NumPy array\n","images_array = np.array(images)\n","\n","# Initialize an empty list to store the std images\n","std_images = []\n","\n","# Loop over the images and compute the std of each group of 24 images\n","for i in range(1, len(images_array) - 23):\n","    group = images_array[i-1:i+23]\n","    std_image = np.std(group, axis=0)\n","    std_images.append(std_image)\n","\n","# Stack the std images into a multi-dimensional array\n","stacked_std_images = np.stack(std_images)\n","\n","# Set the output file name\n","output_file = 'stacked_std_images.npy'\n","\n","# Save the stacked_median_images array as a numpy file\n","np.save(output_file, stacked_std_images)"]},{"cell_type":"markdown","metadata":{"cell_id":"0009fa20e0854dfc80dbfd505ddf7607","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Normalization of  all images"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"a53a4a55ef544dc7912a949ea33b3711","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"fb111d69"},"outputs":[],"source":["#empty list to store normalized images\n","normalized_images = []\n","\n","#loop to normalize images\n","for i in range(25, len(images_array)):\n","    normalized_image=(images_array[i]-stacked_median_images[i-24])/stacked_std_images[i-24]\n","    normalized_images.append(normalized_image)\n","    \n","stacked_nor_images = np.stack(normalized_images)\n","\n","# Define the output directory and file name template\n","#output_dir = 'X:\\STUDENTS\\GROUP_10\\S1 images\\normalizedVV\\ '\n","\n","#name of the images\n","n = 'normalized_'\n","Normalized_name = file_names[24:]\n","\n","image_names =  []\n","\n","for i, img in enumerate(stacked_nor_images):\n","    # Get the corresponding image name from the list\n","    img_name = n + Normalized_name[i]\n","    image_names.append(img_name)\n","print(image_names)\n","\n","# Define some metadata for the output files\n","\n","meta = {'driver': 'GTiff', 'dtype': 'float64', 'nodata': None, 'width': 1217, 'height': 697, 'count': 1, 'crs': 4326, 'transform': Affine(8.983152841195215e-05, 0.0, 110.16534402563957,\n","       0.0, -8.983152841195215e-05, -0.7573696160411686)}\n","\n","# Loop over the images and file names in parallel, and save each image to disk\n","for img, fname in zip(stacked_nor_images, image_names):\n","    with rasterio.open(fname, 'w', **meta) as dst:\n","        dst.write(img, indexes=1)\n"]},{"cell_type":"markdown","metadata":{"cell_id":"1978b8709e054b56a1bba6a8372a851e","deepnote_cell_type":"text-cell-h2","formattedRanges":[]},"source":["## 3. Detection of change"]},{"cell_type":"markdown","metadata":{"cell_id":"f4cb4ab123284a7dbe3b1849f86d29c3","deepnote_cell_type":"text-cell-p","formattedRanges":[]},"source":["In order to detect the change, we set a threshold to reclassify the image in a binary image. We try different thresholds between ... and ... For more accuracy we intersect VV and VH images and apply different filter (no filter, 3x3, 5x5, 7x7) to the intersection images."]},{"cell_type":"markdown","metadata":{"cell_id":"dc611e8c082d49a3a10805d463551974","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Threshold"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"1b3ab62347064d99834838248fff54ae","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"9c70a6f5"},"outputs":[],"source":["# threshold to detect deforestation\n","threshold = -0.5\n","cvt_threshold = str(threshold)\n"]},{"cell_type":"markdown","metadata":{"cell_id":"d2e41225da3e4c59abbca90cc9c2ac90","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Binary VH images"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"afebe61812ac4cba948c34db30561e12","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"461c2982"},"outputs":[],"source":["# Set the directory path\n","dir_path_VH = 'X:/STUDENTS/GROUP_10/S1 images/normalizedVH'\n","\n","# Get the list of file names in the directory\n","file_names_VH = os.listdir(dir_path_VH)\n","\n","# Initialize an empty list to store the images\n","img_VH = []\n","\n","# Loop over the file names and load each image into a NumPy array\n","for file_name in file_names_VH:\n","        # Load the image into a NumPy array\n","        with rasterio.open(os.path.join(dir_path_VH, file_name)) as dataset:\n","            src_VH = dataset.read(1)\n","        # Append the image to the list of images\n","        img_VH.append(src_VH)\n","        \n","#reclassifying the image\n","binary_VH = []\n","\n","for src_VH in img_VH:\n","    binary_array_VH = np.where(src_VH <= threshold, 1, 0)\n","    binary_VH.append(binary_array_VH)"]},{"cell_type":"markdown","metadata":{"cell_id":"a1e7dbbf05b84844868ccdd0a5c25e0e","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Binary VV images"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"0a8aedd1c0b14f4ba19767aa871acb4c","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"56cb3d0b"},"outputs":[],"source":["# Set the directory path\n","dir_path_VV = 'X:/STUDENTS/GROUP_10/S1 images/normalizedVV'\n","\n","# Get the list of file names in the directory\n","file_names_VV = os.listdir(dir_path_VV)\n","\n","# Initialize an empty list to store the images\n","img_VV = []\n","\n","# Loop over the file names and load each image into a NumPy array\n","for file_name in file_names_VV:\n","        # Load the image into a NumPy array\n","        with rasterio.open(os.path.join(dir_path_VV, file_name)) as dataset:\n","            src_VV = dataset.read(1)\n","        # Append the image to the list of images\n","        img_VV.append(src_VV)\n","        \n","#reclassifying the image\n","binary_VV = []\n","\n","for src_VV in img_VV:\n","    binary_array_VV = np.where(src_VV <= threshold, 1, 0)\n","    binary_VV.append(binary_array_VV)"]},{"cell_type":"markdown","metadata":{"cell_id":"ea0241b4fa04452cb32bfc98f1355b29","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Intersection of VV and VH"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"ef7b1ee3aaeb474ca69144aef1dd5a32","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"bf780927"},"outputs":[],"source":["#empty list to store images\n","intersections= []\n","\n","#multiplication of the two binary image VV and VH\n","\n","for VV, VH in zip(binary_VV, binary_VH):\n","    intersection= VV*VH\n","    intersections.append(intersection)"]},{"cell_type":"markdown","metadata":{"cell_id":"6c4bb4d6ff9b4c7d8a4026aa40da0816","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Filter application"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"c600b5e019bf426ba28c8919791816c4","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"5d3f9dc9"},"outputs":[],"source":["#empty list to store images\n","intersections_f= []\n","\n","#set of the filter size\n","filterwindow= 7\n","cvt_filterwindow= str(filterwindow)\n","\n","#Filter application\n","for intersection in intersections:\n","    filtered_img= median_filter(intersection, size=filterwindow)\n","    intersections_f.append(filtered_img)\n"]},{"cell_type":"markdown","metadata":{"cell_id":"0b48c3d2d2c14e53824506efbe752527","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Save each classification images"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"d0863e0ed91041a39b5a57bed827bac1","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"f4c22519"},"outputs":[],"source":["#new empty list to store new names\n","intersection_names = []\n","\n","#loop to create the new names\n","\n","for file_name in file_names_VH:\n","    conserved_part = '_' + '_'.join(file_name.split('_')[4:7])\n","    intersection_name = 'intersection_'+ cvt_threshold +'_'+ cvt_filterwindow + conserved_part  \n","    intersection_names.append(intersection_name)\n","    \n","print(intersection_names)\n","\n","# Define the output directory path\n","output_dir = r\"X:\\STUDENTS\\GROUP_10\\S1 images\\test\"\n","\n","# Create the output directory if it does not exist\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","# Define some metadata for the output files\n","\n","meta = {'driver': 'GTiff', 'dtype': 'float64', 'nodata': None, 'width': 1217, 'height': 697, 'count': 1, 'crs': 4326, 'transform': Affine(8.983152841195215e-05, 0.0, 110.16534402563957,\n","       0.0, -8.983152841195215e-05, -0.7573696160411686)}\n","\n","# Loop over the images and file names in parallel, and save each image to disk\n","for img, fname in zip(intersections_f, intersection_names):\n","    output_path = os.path.join(output_dir, fname )  # Construct the output file path\n","    with rasterio.open(output_path, 'w', **meta) as dst:\n","        dst.write(img, indexes=1)"]},{"cell_type":"markdown","metadata":{"cell_id":"18bb4f9c8cb24e29acadbf58c8492890","deepnote_cell_type":"text-cell-h2","formattedRanges":[]},"source":["## 4. Validation"]},{"cell_type":"markdown","metadata":{"cell_id":"3f826fc63c764027a43038699b67d1ba","deepnote_cell_type":"text-cell-p","formattedRanges":[]},"source":["For the validation, 20 polygons were drawn on QGIS based on an image of planet.com :  10 in the intact forest area and 10 in the deforested area."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"c864227a84bc49cc90f23ec7753bdd08","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"87d07d6b"},"outputs":[],"source":["field_code = 'field'\n","\n","#directory to the polygone layer\n","in_situ_val_shp =\"X:/STUDENTS/GROUP_10/ColineDelmotte/poly/poly_for_nonFor20.shp\"\n","in_situ_val_tif= \"X:/STUDENTS/GROUP_10/validation_points/raster_validation.tif\"\n","\n","# Open the shapefile with GeoPandas\n","in_situ_gdf = gpd.read_file(in_situ_val_shp)\n","\n","# Open the raster file you want to use as a template for rasterize\n","forest_tif = \"X:/STUDENTS/GROUP_10/S1 images/test/intersection_-0.5_5_2021-08_cliped.tif\"\n","src = rasterio.open(forest_tif, \"r\")\n","\n","# Update metadata\n","out_meta = src.meta\n","out_meta.update(nodata=-900)\n","\n","crs_shp = str(in_situ_gdf.crs).split(\":\",1)[1]\n","crs_tif = str(src.crs).split(\":\",1)[1]\n","\n","print(f'The CRS of in situ data is    : {crs_shp}')\n","print(f'The CRS of raster template is : {crs_tif}')"]},{"cell_type":"markdown","metadata":{"cell_id":"00f5b437fda247388f5cae6d1837b2f1","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Rasterization of the polygon layer"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"e81375eec467407fa74df963af45584a","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"3adb2a37"},"outputs":[],"source":["# Burn the features into the raster and write it out\n","dst = rasterio.open(in_situ_val_tif, 'w+', **out_meta)\n","dst_arr = dst.read(1)\n","    \n","# This is where we create a generator of geom, value pairs to use in rasterizing\n","\n","geom_col = in_situ_gdf.geometry\n","code_col = in_situ_gdf[field_code].astype(int)\n","\n","shapes = ((geom,value) for geom, value in zip(geom_col, code_col))\n","\n","in_situ_arr = features.rasterize(shapes=shapes,\n","                                     fill=no_data,\n","                                     out=dst_arr,\n","                                     transform=dst.transform)\n","\n","dst.write_band(1, in_situ_arr)\n","\n","# Close rasterio objects\n","src.close()\n","dst.close()"]},{"cell_type":"markdown","metadata":{"cell_id":"38e240f831854fb295c73be1417bec27","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Build y_pred and y_true"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"5a98e9b9d39c43d898687f6bc8bdb80a","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"3875f8d4"},"outputs":[],"source":["# Open in-situ used for validation\n","src = rasterio.open(in_situ_val_tif, \"r\")\n","val_arr = src.read(1)\n","src.close()\n","\n","# Open classification map\n","src = rasterio.open(forest_tif, \"r\")\n","classif_arr = src.read(1)\n","src.close()\n","\n","# Get the postion of validation pixels\n","idx = np.where(val_arr == -900, 0, 1).astype(bool)\n","\n","# Ground truth (correct) target values\n","y_true = val_arr[idx]\n","print(len(y_true))\n","\n","print(y_true)\n","print(f'Reference data (truth) : {y_true}')\n","\n","# Estimated targets as returned by a classifier.\n","y_pred = classif_arr[idx]\n","\n","print(f'Classification data    : {y_pred}')"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"701256f438df46a68c6ce49d63aa4d62","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"9d51f8e0"},"outputs":[],"source":["# Check if there are missing classes in the classification\n","\n","classes_all  = sorted(np.unique(y_true))\n","classes_pred = sorted(np.unique(y_pred))\n","\n","classes_missing = set(y_true) - set(y_pred)\n","\n","print(f'{len(classes_missing)} classes are missing in the classification (y_pred) : {classes_missing} \\n')\n","\n","print(f'All training classes :\\n {classes_all}')\n","print(f'All predicted classes (at least once) :\\n {classes_pred}')"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"e37f8d2e1338487ab381bc708e0e81b8","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"2edae52c"},"outputs":[],"source":["classes_name = ('forest', 'non forest')\n","\n","for code,name in zip(classes_all, classes_name):\n","    print(f'{code} - {name}')"]},{"cell_type":"markdown","metadata":{"cell_id":"f9f0023a901844ba9fa7292db7f446fb","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Accuracy metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"071e25551d97434fa0a01186585b0f5f","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"d1359f76"},"outputs":[],"source":["acc_metrics_str = classification_report(y_true,  # Exclure la première colonne de y_true\n","                                        y_pred,  # Exclure la première colonne de y_pred\n","                                        target_names=classes_name,\n","                                        labels=classes_all,\n","                                        digits=3,\n","                                        zero_division=0)  # Spécifier la valeur de division par zéro personnalisée\n","\n","print(acc_metrics_str)"]},{"cell_type":"markdown","metadata":{"cell_id":"9e90759633a5490db517a16750c85f71","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Accuracy score"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"c510e6b1ffe249f1aa0b9c742d7a2000","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"9de29a9d"},"outputs":[],"source":["oa = accuracy_score(y_true, y_pred)\n","oa = round(oa*100, 2)\n","\n","print(f'Overall Accuracy : {oa}%')"]},{"cell_type":"markdown","metadata":{"cell_id":"0bad740d32d548d880143f72bb3b7d1d","deepnote_cell_type":"text-cell-h2","formattedRanges":[]},"source":["## 5. Map"]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"80cbd7ed4d624bfb8a9101e2615923c5","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"execution_millis":4,"execution_start":1685087625889,"source_hash":"2958cc4f"},"outputs":[],"source":["im_path = 'C:/Users/karma/Desktop/STUDY_UCL/Land_MonitoringEO/poster/GROUP_10/raster_processed/'\n","\n","images = sorted(glob.glob(f'{im_path}intersection_-0.25_9*cliped.tif'), reverse = True)\n","\n","#basename = os.basename(images[1])\n","\n","new_tif = f'{im_path}CLASSIF_2017-2020_dis-sta___classified_with_combined_model_medianFilter3x3_ALL.tif'#_medianFilter5x5_ALL.tif'\n","\n","nodata_val = -1000\n","\n","ref_img = rasterio.open(images[1], \"r\", driver='GTiff')\n","\n","profile = ref_img.profile\n","profile.update(\n","        dtype=rasterio.float32,  # Set to int16 it is lighter than float\n","        count=1,                 # We will write 1 band by file\n","        nodata=nodata_val,       # Set nodata value in metadata\n","        compress='lzw'           # Compression option)\n",")\n","\n","new = np.full(ref_img.shape, nodata_val, dtype='float32')\n","\n","ref_img.close()\n","\n","for img in images:\n","    \n","    date_1 = os.path.basename(img)[21:25]\n","    date_2 = os.path.basename(img)[26:28]\n","    date = int(date_1 + date_2)\n","    \n","    # print(f'dates{date}')\n","    # print(f'dates{date_1}')\n","    # print(f'dates{date_2}')\n","    \n","    img = rasterio.open(img, \"r\", driver='GTiff')\n","    im = img.read(1)\n","    \n","   \n","    im = im.astype('float32')\n","    im = np.nan_to_num(im, nan=nodata_val)\n","    \n","\n","    im[np.where(im == 0)] = 0\n","    im[np.where(im == 1)] = date\n","\n","    print(\"Number of dates = {}\".format(np.count_nonzero(im == date)))\n","    \n","    mask = np.where(im != 0)\n","    \n","    new[mask] = im[mask]\n","\n","\n","print(np.unique(new))\n","\n","im_dst = rasterio.open(new_tif, \"w\", **profile)\n","im_dst.write(new, 1)\n","im_dst.close()"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=b812eaa8-a356-401a-a7e5-fb6c6f64af60' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"040e8acaa7844007a7cd47a10e6e92f0","deepnote_persisted_session":{"createdAt":"2023-05-26T08:16:22.400Z"},"language_info":{"name":"python"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
